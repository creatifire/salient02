<!--
Copyright (c) 2025 Ape4, Inc. All rights reserved.
Unauthorized copying of this file is strictly prohibited.
-->

# Bug Report: Epic 0023 Directory Service

> **Last Updated**: October 29, 2025  
> **Epic**: [0023-directory-service.md](0023-directory-service.md)

## Summary

1. **BUG-0023-001** (P0): SQLAlchemy concurrent operations error during parallel tool execution üî¥
2. **BUG-0023-002** (P1): Configuration cascade looking in wrong path üü°
3. **BUG-0023-003** (P2): Connection pool sizing insufficient for concurrent load üü¢

**Impact**: Parallel tool calls ‚Üí cost tracking failures ‚Üí lost billing data

**Test Source**: `memorybank/analysis/llm-tool-calling-evaluation.md` lines 115-138

---

## BUG-0023-001: SQLAlchemy Concurrent Operations Error üî¥ P0

### Problem

Parallel tool calls (2x `search_directory`) cause cost tracking to fail with "concurrent operations are not permitted". Results in `llm_request_id: None` and lost billing data.

**Evidence**:
```python
"Cost tracking failed: This session is provisioning a new connection; 
concurrent operations are not permitted"
# llm_request_id: None, response_length: 24 (normal: 4000+)
```

### Root Cause

Shared database session across concurrent operations:
1. LLM makes 2 parallel tool calls
2. Tools query database (session "provisioning")
3. Cost tracking tries to write concurrently
4. SQLAlchemy rejects: session mid-transaction

**Location**: `SessionDependencies.db_session` shared between tools and cost tracker

### Impact

- Lost billing data (unbilled LLM usage)
- Audit trail gaps
- Cannot analyze parallel tool performance

### Fix Options

#### Option A: Sequential Tool Execution

Force tools to run one-by-one. **Not recommended** - defeats parallel tool calling purpose.

**Trade-off**: 2.4s ‚Üí 4.8s for 2 tools

---

#### Option B: Session-per-Operation ‚≠ê **Long-term Solution**

Each operation creates its own session. See **[bugs-0023-001-option-b-revised-plan.md](bugs-0023-001-option-b-revised-plan.md)** for full implementation.

**Core concept**:
```python
@agent.tool
async def search_directory(...):
    async with get_db_session() as session:  # Independent session
        return await directory_service.search(session, ...)

async def track_request(...):
    async with get_db_session() as session:  # Independent session
        session.add(llm_request)
        await session.commit()
```

**Pros**: Proper architecture, scalable, eliminates conflicts  
**Cons**: 2-3 days effort, requires testing across agents  
**Effort**: 2-3 days

---

#### Option C: Deferred Cost Tracking ‚≠ê **Quick Fix**

Track costs after tools complete, not during execution.

```python
async def simple_chat_stream(...):
    cost_data = {...}  # Store in memory
    
    # 1. Execute LLM (tools run in parallel)
    async for chunk in result.stream_text(delta=True):
        yield chunk
    
    # 2. After completion, write to database
    llm_request_id = await llm_request_tracker.track_request(**cost_data)
```

**Pros**: Minimal changes, preserves parallel execution  
**Cons**: Costs lost if crash mid-stream  
**Effort**: 2-4 hours

### Recommendation

- **Phase 1** (This Week): Implement Option C
- **Phase 2** (Next Quarter): Implement Option B - [See detailed plan](bugs-0023-001-option-b-revised-plan.md)

---

## BUG-0023-002: Configuration Cascade Path Error üü° P1

### Problem

Config loader uses wrong path: looks for `agent_configs/simple_chat/config.yaml` instead of `agent_configs/wyckoff/wyckoff_info_chat1/config.yaml`. All agents fall back to global config.

### Fix

Update path construction in config loader:

```python
# Before (wrong)
config_path = f"agent_configs/{agent_type}/config.yaml"

# After (correct)
config_path = f"agent_configs/{account_slug}/{instance_slug}/config.yaml"
```

**Files**: `backend/app/agents/cascade_monitor.py` or config loader  
**Effort**: 1-2 hours

---

## BUG-0023-003: Connection Pool Sizing üü¢ P2

### Problem

`max_overflow=0` means no burst capacity. May exhaust pool under concurrent load.

### Fix

```python
engine = create_async_engine(
    pool_size=20,
    max_overflow=10,      # Add burst capacity (total: 30)
    pool_pre_ping=True,   # Verify connections
)
```

**Timeline**: After BUG-001 fixed, before production

---

## Fix Priority

1. **BUG-001** (P0): Option C immediate, Option B long-term
2. **BUG-002** (P1): Config path (1-2 hours)
3. **BUG-003** (P2): Pool sizing (after BUG-001)

---

**Created**: 2025-10-29 | **Epic**: [0023-directory-service.md](0023-directory-service.md)
