# Epic 0026 - Simple Admin Frontend for Chat Tracing

**Status**: Draft  
**Created**: 2025-11-12  
**Priority**: Medium  
**Category**: Developer Tools / Debugging

---

## Purpose

Debug LLM tool selection and prompt composition issues via simple admin UI.

**Core Features**:
- Browse sessions by account/agent
- View conversation history with LLM metadata
- Inspect prompt breakdown (critical rules, modules, directory docs)
- Trace tool calls (which tool, why, with what args)

**Primary Use Case**: Debug why LLM chooses wrong tools (e.g., `vector_search` instead of `search_directory` for phone queries)

---

## Technology Stack

- **Frontend**: Astro + Preact (already installed)
- **Backend**: FastAPI
- **Styling**: TailwindCSS (already installed)
- **Auth**: HTTP Basic Auth for `/api/admin/*`

---

## Routes

### `/admin/sessions` - Session List
Table with filters (account, agent, date range) showing session metadata and message counts.

**API**: `GET /api/admin/sessions?account={slug}&agent={slug}&limit=50&offset=0`

### `/admin/sessions/{id}` - Session Detail
Conversation timeline with expandable LLM request details (model, tokens, cost, tool calls) and prompt inspector sidebar.

**APIs**: 
- `GET /api/admin/sessions/{id}/messages`
- `GET /api/admin/llm-requests/{request_id}`

### `/admin/llm-requests/{id}` - LLM Request Deep Dive (Optional)
Full prompt breakdown with accordion sections, tool call analysis, and raw JSON views.

---

## Implementation Plan

### Phase 0: Foundation Setup

#### Task 0026-000-001: Add meta Column
```sql
ALTER TABLE llm_requests ADD COLUMN meta JSONB;
```

#### Task 0026-000-002: Create PromptBreakdownService

**What it does**: Captures how the LLM prompt was assembled (what sections, in what order, how long each section is). This data gets stored in the database so the admin UI can show exactly what prompt the LLM saw when it made a bad decision.

**Why it matters**: When debugging "why did the LLM choose the wrong tool?", you need to see the exact prompt it received. This service tracks all the pieces (critical rules, base prompt, directory docs, modules) and their positions.

**File**: `backend/app/services/prompt_breakdown_service.py`

```python
from typing import Dict, Optional
import logfire

class PromptBreakdownService:
    @staticmethod
    def capture_breakdown(
        base_prompt: str,
        critical_rules: Optional[str] = None,
        directory_docs: Optional[str] = None,
        modules: Optional[Dict[str, str]] = None,
        account_slug: Optional[str] = None,
        agent_instance_slug: Optional[str] = None
    ) -> dict:
        breakdown = {"sections": []}
        position = 1
        total_chars = 0
        
        if critical_rules:
            breakdown["sections"].append({
                "name": "critical_rules",
                "position": position,
                "char_count": len(critical_rules),
                "source": "tool_selection_hints.md"
            })
            total_chars += len(critical_rules)
            position += 1
        
        breakdown["sections"].append({
            "name": "base_prompt",
            "position": position,
            "char_count": len(base_prompt),
            "source": "system_prompt.md"
        })
        total_chars += len(base_prompt)
        position += 1
        
        if directory_docs:
            breakdown["sections"].append({
                "name": "directory_docs",
                "position": position,
                "char_count": len(directory_docs),
                "source": "auto-generated"
            })
            total_chars += len(directory_docs)
            position += 1
        
        if modules:
            for module_name, content in modules.items():
                breakdown["sections"].append({
                    "name": module_name,
                    "position": position,
                    "char_count": len(content),
                    "source": f"{module_name}.md"
                })
                total_chars += len(content)
                position += 1
        
        breakdown["total_char_count"] = total_chars
        
        logfire.info(
            'service.prompt_breakdown.captured',
            account_slug=account_slug,
            agent_instance_slug=agent_instance_slug,
            total_chars=total_chars
        )
        
        return breakdown
```

#### Task 0026-000-003: Integrate into simple_chat.py
**Changes**: `simple_chat.py`, `cost_calculator.py`, `llm_request_tracker.py`

```python
# simple_chat.py - In create_simple_chat_agent()
from ..services.prompt_breakdown_service import PromptBreakdownService

breakdown = PromptBreakdownService.capture_breakdown(
    base_prompt=base_system_prompt,
    critical_rules=critical_rules if critical_rules else None,
    directory_docs=directory_docs if directory_config.get("enabled") else None,
    modules={name: load_prompt_module(name, account_slug) 
             for name in prompting_config.get('selected', [])} if prompting_config.get('enabled') else None,
    account_slug=account_slug,
    agent_instance_slug=instance_config.get('slug') if instance_config else None
)

# cost_calculator.py - Add prompt_breakdown parameter
async def track_chat_request(
    tracker: Any,
    # ... existing params ...
    prompt_breakdown: Optional[dict] = None  # NEW
) -> Optional[UUID]:
    llm_request_id = await tracker.track_llm_request(
        # ... existing params ...
        meta={"prompt_breakdown": prompt_breakdown} if prompt_breakdown else None
    )

# llm_request_tracker.py - Add meta parameter
async def track_llm_request(
    self,
    # ... existing params ...
    meta: Optional[Dict[str, Any]] = None  # NEW
) -> UUID:
    llm_request = LLMRequest(
        # ... existing fields ...
        meta=meta
    )
```

#### Task 0026-000-004: Verify Tool Call Storage
Check if `message.meta["tool_calls"]` is populated. If missing:

```python
# In simple_chat() after agent.run()
tool_calls_meta = []
if result.all_messages():
    for msg in result.all_messages():
        if hasattr(msg, 'parts'):
            for part in msg.parts:
                if isinstance(part, ToolCallPart):
                    tool_calls_meta.append({
                        "tool_name": part.tool_name,
                        "args": part.args
                    })

await message_service.save_message(
    # ...
    meta={"tool_calls": tool_calls_meta} if tool_calls_meta else None
)
```

#### Task 0026-000-005: Admin Auth Middleware
**File**: `backend/app/middleware/admin_auth_middleware.py`

```python
import os
import secrets
import base64
from typing import Callable
from fastapi import Request, status
from starlette.middleware.base import BaseHTTPMiddleware
from fastapi.responses import JSONResponse
import logfire

class AdminAuthMiddleware(BaseHTTPMiddleware):
    def __init__(self, app):
        super().__init__(app)
        self.admin_username = os.getenv("ADMIN_USERNAME", "admin")
        self.admin_password = os.getenv("ADMIN_PASSWORD", "changeme")
        
        if self.admin_password == "changeme":
            logfire.warn('security.admin_auth.default_password',
                        message="Change ADMIN_PASSWORD env var")
    
    async def dispatch(self, request: Request, call_next: Callable):
        if not request.url.path.startswith("/api/admin/"):
            return await call_next(request)
        
        auth_header = request.headers.get("Authorization")
        if not auth_header or not auth_header.startswith("Basic "):
            return self._unauthorized()
        
        try:
            credentials = base64.b64decode(auth_header[6:]).decode("utf-8")
            username, password = credentials.split(":", 1)
            
            if not (secrets.compare_digest(username, self.admin_username) and 
                    secrets.compare_digest(password, self.admin_password)):
                logfire.warn('security.admin_auth.failed', username=username)
                return self._unauthorized()
            
            logfire.info('security.admin_auth.success', username=username,
                        ip=request.client.host if request.client else None)
        except Exception as e:
            logfire.error('security.admin_auth.error', error=str(e))
            return self._unauthorized()
        
        return await call_next(request)
    
    def _unauthorized(self):
        return JSONResponse(
            status_code=status.HTTP_401_UNAUTHORIZED,
            content={"detail": "Admin authentication required"},
            headers={"WWW-Authenticate": "Basic realm=\"Admin Area\""}
        )
```

**Register in `main.py`**:
```python
from .middleware.admin_auth_middleware import AdminAuthMiddleware
app.add_middleware(AdminAuthMiddleware)
```

**`.env`**:
```bash
ADMIN_USERNAME=admin
ADMIN_PASSWORD=your-secure-password-here
```

---

### Phase 1: Backend API Endpoints

#### Feature 0026-001: Sessions List API
**File**: `backend/app/api/admin.py`

```python
from fastapi import APIRouter, Query
from sqlalchemy import select, func
from ..models import Session, Message

router = APIRouter(prefix="/api/admin", tags=["admin"])

@router.get("/sessions")
async def list_sessions(
    account: str = Query(None),
    agent: str = Query(None),
    limit: int = Query(50, le=100),
    offset: int = Query(0, ge=0)
):
    # Query sessions with filters
    # Join with messages for count
    # Return paginated results
    pass
```

#### Feature 0026-002: Session Messages API
```python
@router.get("/sessions/{session_id}/messages")
async def get_session_messages(session_id: str):
    # Query messages for session
    # Join with llm_requests for metadata
    # Return chronological list
    pass
```

#### Feature 0026-003: LLM Request Detail API
```python
@router.get("/llm-requests/{request_id}")
async def get_llm_request(request_id: str):
    # Query llm_requests table
    # Return prompt_breakdown from meta field
    # Include tool calls and response
    pass
```

---

### Phase 2: Frontend Pages

#### Feature 0026-004: Session List Page
**File**: `web/src/pages/admin/sessions.astro`
- Server-side fetch sessions on load
- Embed `<SessionFilters client:load />` Preact component for interactivity
- TailwindCSS table styling

**Component**: `web/src/components/admin/SessionFilters.tsx`
```tsx
import { h } from 'preact';
import { useState, useEffect } from 'preact/hooks';

export function SessionFilters() {
  const [account, setAccount] = useState('');
  const [sessions, setSessions] = useState([]);
  const [loading, setLoading] = useState(false);

  useEffect(() => {
    const fetchSessions = async () => {
      setLoading(true);
      const params = new URLSearchParams();
      if (account) params.append('account', account);
      const response = await fetch(`/api/admin/sessions?${params}`);
      const data = await response.json();
      setSessions(data.sessions || []);
      setLoading(false);
    };
    fetchSessions();
  }, [account]);

  return (
    <div class="p-4">
      <select value={account} onChange={(e) => setAccount(e.currentTarget.value)}
              class="border rounded p-2">
        <option value="">All Accounts</option>
        <option value="wyckoff">Wyckoff</option>
      </select>
      
      {loading ? <div>Loading...</div> : (
        <table class="w-full mt-4">
          {/* Render sessions */}
        </table>
      )}
    </div>
  );
}
```

#### Feature 0026-005: Session Detail Page
**File**: `web/src/pages/admin/sessions/[id].astro`
- Dynamic route with session ID
- Server-side fetch messages
- Conversation timeline with Preact components

**Component**: `web/src/components/admin/PromptInspector.tsx`
```tsx
import { h } from 'preact';
import { useState } from 'preact/hooks';

export function PromptInspector({ requestId }: { requestId: string }) {
  const [breakdown, setBreakdown] = useState(null);
  const [expanded, setExpanded] = useState(null);

  const loadBreakdown = async () => {
    const response = await fetch(`/api/admin/llm-requests/${requestId}`);
    const data = await response.json();
    setBreakdown(data.prompt_breakdown);
  };

  return (
    <aside class="border-l p-4">
      <h3 class="font-bold mb-4">Prompt Inspector</h3>
      {breakdown && breakdown.sections.map((section) => (
        <div key={section.name} class="mb-2">
          <button 
            onClick={() => setExpanded(expanded === section.name ? null : section.name)}
            class="w-full text-left p-2 bg-gray-100 hover:bg-gray-200 rounded">
            {section.name} ({section.char_count} chars)
          </button>
          {expanded === section.name && (
            <pre class="p-2 bg-gray-50 text-sm overflow-auto">
              <code>{section.content}</code>
            </pre>
          )}
        </div>
      ))}
    </aside>
  );
}
```

---

## File Structure

```
web/src/
├── pages/admin/
│   ├── index.astro                      # Redirect to /admin/sessions
│   ├── sessions.astro                   # Session list
│   └── sessions/[id].astro              # Session detail
├── components/admin/
│   ├── SessionFilters.tsx               # Filter component
│   ├── SessionTable.tsx                 # Interactive table
│   ├── MessageDetails.tsx               # LLM metadata
│   └── PromptInspector.tsx              # Prompt breakdown

backend/app/
├── api/admin.py                          # Admin endpoints
├── middleware/admin_auth_middleware.py   # HTTP Basic Auth
└── services/prompt_breakdown_service.py  # Breakdown capture
```

---

## API Response Schemas

### Sessions List
```json
{
  "sessions": [{
    "id": "uuid",
    "account_slug": "wyckoff",
    "agent_instance_slug": "wyckoff_info_chat1",
    "created_at": "2025-11-12T20:46:10Z",
    "message_count": 4
  }],
  "total": 42,
  "limit": 50,
  "offset": 0
}
```

### Session Messages
```json
{
  "session_id": "uuid",
  "messages": [{
    "id": "uuid",
    "role": "user",
    "content": "what is the number of the pharmacy",
    "created_at": "2025-11-12T20:47:49Z"
  }, {
    "id": "uuid",
    "role": "assistant",
    "content": "I don't have the specific phone number...",
    "llm_request_id": "uuid",
    "meta": {
      "model": "google/gemini-2.5-flash",
      "input_tokens": 15410,
      "cost": 0.04623,
      "tool_calls": [{"tool_name": "vector_search", "args": {...}}]
    }
  }]
}
```

### LLM Request Detail
```json
{
  "id": "uuid",
  "model": "google/gemini-2.5-flash",
  "prompt_breakdown": {
    "sections": [
      {"name": "critical_rules", "char_count": 4928, "source": "tool_selection_hints.md"},
      {"name": "base_prompt", "char_count": 3200, "source": "system_prompt.md"},
      {"name": "directory_docs", "char_count": 6100, "source": "auto-generated"}
    ],
    "total_char_count": 14228
  },
  "tool_calls": [
    {"tool_name": "vector_search", "args": {"query": "phone number"}}
  ],
  "response": {
    "content": "I don't have the specific phone number...",
    "input_tokens": 15410,
    "cost": 0.04623
  }
}
```

---

## Dependencies

- Astro 5.13.0 (installed)
- Preact 10.27.0 (installed)
- @astrojs/preact 4.1.0 (installed)
- TailwindCSS 4.1.12 (installed)
- FastAPI (installed)
- SQLAlchemy (installed)

---

## Related Documents

- `memorybank/architecture/agent-and-tool-design.md`
- `memorybank/design/dynamic-prompting.md`
- `memorybank/design/prompt-modules.md`
- `memorybank/project-management/0025-dynamic-prompting-plan.md`
