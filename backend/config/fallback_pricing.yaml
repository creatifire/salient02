# Fallback pricing for models not yet in genai-prices database
# Used when genai-prices.calc_price() raises LookupError
#
# Format:
#   model_id:
#     input_per_1m: Cost in USD per 1 million input tokens
#     output_per_1m: Cost in USD per 1 million output tokens
#     source: URL documenting the pricing
#     updated: Date pricing was last verified (YYYY-MM-DD)
#
# When to add a model here:
# - Model is available on OpenRouter but not in genai-prices yet
# - Streaming cost calculation fails with LookupError
# - Check logs for: "streaming_cost_calculation_failed" with "LookupError"
#
# Pricing Source:
# - For models accessed via OpenRouter, use: https://openrouter.ai/{provider}/{model}
# - Example: https://openrouter.ai/moonshotai/kimi-k2-0905
# - OpenRouter provides official pricing for all models on their platform
#
# Maintenance:
# - Verify pricing monthly or when model providers announce changes
# - Remove models once they appear in genai-prices (check periodically)
# - Document source URL for each model's pricing

models:
  moonshotai/kimi-k2-0905:
    input_per_1m: 0.39    # $0.39 per 1M input tokens
    output_per_1m: 1.90   # $1.90 per 1M output tokens
    source: "https://openrouter.ai/moonshotai/kimi-k2-0905"
    updated: "2025-10-15"
    notes: "Primary model for default_account/simple_chat1 (September 2025 update, 256k context)"
  
  moonshotai/kimi-k2:
    input_per_1m: 0.14    # $0.14 per 1M input tokens
    output_per_1m: 2.49   # $2.49 per 1M output tokens
    source: "https://openrouter.ai/moonshotai/kimi-k2"
    updated: "2025-10-15"
    notes: "Alias for kimi-k2-0711 (July 2025 version, 63k context)"
    
  openai/gpt-oss-120b:
    input_per_1m: 0.04     # $0.04 per 1M input tokens
    output_per_1m: 0.40    # $0.40 per 1M output tokens
    source: "https://openrouter.ai/models?q=gpt-oss-120b"
    updated: "2025-10-14"
    notes: "Used by default_account/simple_chat2"
  
  qwen/qwen3-235b-a22b-thinking-2507:
    input_per_1m: 0.11     # $0.11 per 1M input tokens
    output_per_1m: 0.60    # $0.60 per 1M output tokens
    source: "https://openrouter.ai/qwen/qwen3-235b-a22b-thinking-2507"
    updated: "2025-10-17"
    notes: "Thinking-only variant optimized for complex reasoning, math, science. 262k context, activates 22B of 235B params. MoE model."
  
  openai/gpt-5:
    input_per_1m: 1.25     # $1.25 per 1M input tokens
    output_per_1m: 10.00   # $10.00 per 1M output tokens
    source: "https://openrouter.ai/openai/gpt-5"
    updated: "2025-10-20"
    notes: "OpenAI flagship GPT-5 model (Aug 2025). Used by wyckoff/wyckoff_info_chat1. 400k context, 128k max output. SUPPORTS TOOLS (vector search, reasoning). Major improvements in reasoning, code quality, and accuracy vs GPT-4."
  
  openai/gpt-5-chat:
    input_per_1m: 1.25     # $1.25 per 1M input tokens
    output_per_1m: 10.00   # $10.00 per 1M output tokens
    source: "https://openrouter.ai/openai/gpt-5-chat"
    updated: "2025-10-20"
    notes: "DIFFERENT MODEL from openai/gpt-5. Conversational variant for enterprise apps. 128k context (smaller than gpt-5's 400k). Tool support unknown - use openai/gpt-5 or gpt-5-mini for tool-enabled agents."
  
  openai/gpt-5-mini:
    input_per_1m: 0.25     # $0.25 per 1M input tokens
    output_per_1m: 2.00    # $2.00 per 1M output tokens
    source: "https://openrouter.ai/openai/gpt-5-mini"
    updated: "2025-10-18"
    notes: "Used by wyckoff/wyckoff_info_chat1. Compact GPT-5 for lighter reasoning. Supports tool use. 400k context. 80% cheaper than gpt-5-chat."
  
  deepseek/deepseek-v3.2-exp:
    input_per_1m: 0.27     # $0.27 per 1M input tokens
    output_per_1m: 0.40    # $0.40 per 1M output tokens
    source: "https://openrouter.ai/deepseek/deepseek-v3.2-exp"
    updated: "2025-09-29"
    notes: "Experimental model with DeepSeek Sparse Attention (DSA) for long-context efficiency. Supports tool calling. 163k context. Research-oriented architecture validation."
  
  anthropic/claude-haiku-4.5:
    input_per_1m: 1.00     # $1.00 per 1M input tokens
    output_per_1m: 5.00    # $5.00 per 1M output tokens
    source: "https://openrouter.ai/anthropic/claude-haiku-4.5"
    updated: "2025-10-18"
    notes: "Fastest Anthropic model with near-frontier intelligence. Extended thinking, full tool support (coding, bash, web search, computer-use). >73% SWE-bench Verified. 200k context. Created Oct 15, 2025. NOTE: Inconsistent tool-calling in streaming mode (sometimes announces 'I'll search...' without completing)."
  
  # NOTE: google/gemini-2.5-flash is available in genai-prices (as "gemini-2.5-flash")
  # No fallback entry needed - code strips provider prefix before calling calc_price()

