import os
import asyncio
from decimal import Decimal
from typing import Optional, Dict, Any
from pydantic import BaseModel, Field
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIChatModel
from pydantic_ai.providers.openrouter import OpenRouterProvider
from dotenv import load_dotenv
from pathlib import Path

# Load environment variables from .env file at project root
backend_dir = Path(__file__).parent.parent.parent
load_dotenv(backend_dir.parent / ".env")

class ChatResponse(BaseModel):
    """Response model for chat interactions."""
    message: str = Field(..., description="The chat response message")
    reasoning: Optional[str] = Field(None, description="Optional reasoning behind the response")

class CostTrackingData(BaseModel):
    """Model for cost tracking data from OpenRouter."""
    total_cost: Decimal = Field(..., description="Total cost of the request")
    prompt_cost: Decimal = Field(..., description="Cost for prompt tokens")
    completion_cost: Decimal = Field(..., description="Cost for completion tokens")
    prompt_tokens: int = Field(..., description="Number of prompt tokens")
    completion_tokens: int = Field(..., description="Number of completion tokens")
    total_tokens: int = Field(..., description="Total tokens used")
    model_name: str = Field(..., description="Model used for the request")

class HybridPydanticAIWithCostTracking:
    """
    Hybrid solution combining Pydantic AI capabilities with accurate OpenRouter cost tracking.
    
    This solution:
    1. Uses Pydantic AI for structured outputs and agent capabilities
    2. Accesses the underlying OpenRouter client for cost-enabled API calls
    3. Provides accurate billing data for customer charging
    """
    
    def __init__(self, api_key: str, model_name: str = "openai/gpt-3.5-turbo"):
        self.api_key = api_key
        self.model_name = model_name
        
        # Create OpenRouterProvider (works without validation errors!)
        self.provider = OpenRouterProvider(api_key=api_key)
        
        # Access the underlying client for direct cost-enabled calls
        self.direct_client = self.provider.client
        
        # Create Pydantic AI agent for structured outputs
        model_instance = OpenAIChatModel(
            model_name=model_name,
            provider=self.provider
        )
        
        self.agent = Agent(
            model=model_instance,
            output_type=ChatResponse,
        )
    
    async def chat_with_cost_tracking(self, prompt: str) -> tuple[ChatResponse, CostTrackingData]:
        """
        Chat with both structured output AND accurate cost tracking.
        
        Returns:
            tuple[ChatResponse, CostTrackingData]: Response and cost data
        """
        
        # Method 1: Use Pydantic AI for structured output (no cost data)
        pydantic_result = await self.agent.run(prompt)
        structured_response = pydantic_result.output
        
        # Method 2: Make parallel direct call for cost data
        cost_response = await self.direct_client.chat.completions.create(
            model=self.model_name,
            messages=[{"role": "user", "content": prompt}],
            extra_body={"usage": {"include": True}}  # Critical for OpenRouter cost data
        )
        
        # Extract cost data
        usage = cost_response.usage
        cost_data = CostTrackingData(
            total_cost=Decimal(str(usage.cost)),
            prompt_cost=Decimal(str(usage.cost_details['upstream_inference_prompt_cost'])),
            completion_cost=Decimal(str(usage.cost_details['upstream_inference_completions_cost'])),
            prompt_tokens=usage.prompt_tokens,
            completion_tokens=usage.completion_tokens,
            total_tokens=usage.total_tokens,
            model_name=self.model_name
        )
        
        return structured_response, cost_data
    
    async def advanced_chat_single_call(self, prompt: str) -> tuple[str, CostTrackingData]:
        """
        Alternative: Single call approach for basic responses.
        Gets both response and cost data from one API call.
        """
        
        response = await self.direct_client.chat.completions.create(
            model=self.model_name,
            messages=[{"role": "user", "content": prompt}],
            extra_body={"usage": {"include": True}}
        )
        
        # Extract response content
        message_content = response.choices[0].message.content
        
        # Extract cost data
        usage = response.usage
        cost_data = CostTrackingData(
            total_cost=Decimal(str(usage.cost)),
            prompt_cost=Decimal(str(usage.cost_details['upstream_inference_prompt_cost'])),
            completion_cost=Decimal(str(usage.cost_details['upstream_inference_completions_cost'])),
            prompt_tokens=usage.prompt_tokens,
            completion_tokens=usage.completion_tokens,
            total_tokens=usage.total_tokens,
            model_name=self.model_name
        )
        
        return message_content, cost_data

async def demo_hybrid_solution():
    """
    Demonstrate the hybrid solution in action.
    """
    api_key = os.getenv("OPENROUTER_API_KEY")
    if not api_key:
        print("‚ùå OPENROUTER_API_KEY not found")
        return
    
    print("üèÜ HYBRID SOLUTION: Pydantic AI + OpenRouter Cost Tracking")
    print("=" * 65)
    
    # Create hybrid solution
    hybrid = HybridPydanticAIWithCostTracking(
        api_key=api_key,
        model_name="openai/gpt-3.5-turbo"
    )
    
    # Test structured output with cost tracking
    print("ü¶ú Testing structured output with cost tracking...")
    prompt = "Explain why the sky is blue in simple terms"
    
    structured_response, cost_data = await hybrid.chat_with_cost_tracking(prompt)
    
    print(f"\n‚úÖ STRUCTURED RESPONSE:")
    print(f"   Message: '{structured_response.message[:80]}...'")
    print(f"   Reasoning: {structured_response.reasoning}")
    
    print(f"\nüí∞ ACCURATE COST DATA:")
    print(f"   Total Cost: ${cost_data.total_cost:.6f}")
    print(f"   Prompt Cost: ${cost_data.prompt_cost:.6f}")
    print(f"   Completion Cost: ${cost_data.completion_cost:.6f}")
    print(f"   Tokens: {cost_data.prompt_tokens} + {cost_data.completion_tokens} = {cost_data.total_tokens}")
    print(f"   Model: {cost_data.model_name}")
    
    # Test single call approach
    print(f"\nüîß Testing single call approach...")
    simple_prompt = "What is 2+2?"
    
    simple_response, simple_cost = await hybrid.advanced_chat_single_call(simple_prompt)
    
    print(f"\n‚úÖ SIMPLE RESPONSE: '{simple_response}'")
    print(f"üí∞ COST: ${simple_cost.total_cost:.6f} ({simple_cost.total_tokens} tokens)")
    
    print(f"\nüéØ HYBRID SOLUTION BENEFITS:")
    print("‚úÖ Pydantic AI agent capabilities (structured outputs, validation)")
    print("‚úÖ Real OpenRouter cost data (accurate to the penny)")
    print("‚úÖ Customer billing ready (exact costs, no estimates)")
    print("‚úÖ Production ready (handles both simple and complex use cases)")
    print("‚úÖ No framework limitations (direct API access when needed)")

if __name__ == "__main__":
    asyncio.run(demo_hybrid_solution())
